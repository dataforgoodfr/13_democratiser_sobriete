{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04d4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc62620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing buildings dataset\n",
      "Processing digitalisation dataset\n",
      "Processing freight dataset\n",
      "Processing mobility dataset\n",
      "Processing nutrition dataset\n",
      "Processing urban_ecology dataset\n",
      "Processing urban_governance dataset\n",
      "Processing urban_infra dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>true_label</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Young Households' Diminishing Access to Homeow...</td>\n",
       "      <td>This multi-country article focuses particularl...</td>\n",
       "      <td>0</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wood buildings as a climate solution</td>\n",
       "      <td>We conducted a systematic literature search an...</td>\n",
       "      <td>0</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Winners and Losers in Housing Markets</td>\n",
       "      <td>This paper is a quantitatively oriented theore...</td>\n",
       "      <td>0</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Window opening behavior of occupants in reside...</td>\n",
       "      <td>Window opening behavior has a vital influence ...</td>\n",
       "      <td>0</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wind driven natural ventilation in the idealiz...</td>\n",
       "      <td>Improved ventilation in an urban residential n...</td>\n",
       "      <td>0</td>\n",
       "      <td>buildings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6733</th>\n",
       "      <td>Legal Guarantee of Smart City Pilot and Green ...</td>\n",
       "      <td>Green and smart cities are based on clean ener...</td>\n",
       "      <td>7</td>\n",
       "      <td>urban_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>Legal Guarantee of Smart City Pilot and Green ...</td>\n",
       "      <td>Green and smart cities are based on clean ener...</td>\n",
       "      <td>7</td>\n",
       "      <td>urban_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6735</th>\n",
       "      <td>Sustainable Urban Resource Management an Analy...</td>\n",
       "      <td>Conference Title: 2024 6th International Confe...</td>\n",
       "      <td>7</td>\n",
       "      <td>urban_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>Efficiency of green and low-carbon coordinated...</td>\n",
       "      <td>As a critical engine for national economic gro...</td>\n",
       "      <td>7</td>\n",
       "      <td>urban_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>Spatiotemporal Evolution and Rank–Size Pattern...</td>\n",
       "      <td>Accurate and timely urban boundaries can effec...</td>\n",
       "      <td>7</td>\n",
       "      <td>urban_infra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6657 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Young Households' Diminishing Access to Homeow...   \n",
       "1                  Wood buildings as a climate solution   \n",
       "2                 Winners and Losers in Housing Markets   \n",
       "3     Window opening behavior of occupants in reside...   \n",
       "4     Wind driven natural ventilation in the idealiz...   \n",
       "...                                                 ...   \n",
       "6733  Legal Guarantee of Smart City Pilot and Green ...   \n",
       "6734  Legal Guarantee of Smart City Pilot and Green ...   \n",
       "6735  Sustainable Urban Resource Management an Analy...   \n",
       "6736  Efficiency of green and low-carbon coordinated...   \n",
       "6737  Spatiotemporal Evolution and Rank–Size Pattern...   \n",
       "\n",
       "                                               abstract  true_label  \\\n",
       "0     This multi-country article focuses particularl...           0   \n",
       "1     We conducted a systematic literature search an...           0   \n",
       "2     This paper is a quantitatively oriented theore...           0   \n",
       "3     Window opening behavior has a vital influence ...           0   \n",
       "4     Improved ventilation in an urban residential n...           0   \n",
       "...                                                 ...         ...   \n",
       "6733  Green and smart cities are based on clean ener...           7   \n",
       "6734  Green and smart cities are based on clean ener...           7   \n",
       "6735  Conference Title: 2024 6th International Confe...           7   \n",
       "6736  As a critical engine for national economic gro...           7   \n",
       "6737  Accurate and timely urban boundaries can effec...           7   \n",
       "\n",
       "           origin  \n",
       "0       buildings  \n",
       "1       buildings  \n",
       "2       buildings  \n",
       "3       buildings  \n",
       "4       buildings  \n",
       "...           ...  \n",
       "6733  urban_infra  \n",
       "6734  urban_infra  \n",
       "6735  urban_infra  \n",
       "6736  urban_infra  \n",
       "6737  urban_infra  \n",
       "\n",
       "[6657 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sector_list = [\n",
    "    \"buildings\",\n",
    "    \"digitalisation\",\n",
    "    \"freight\",\n",
    "    \"mobility\",\n",
    "    \"nutrition\",\n",
    "    \"urban_ecology\",\n",
    "    \"urban_governance\",\n",
    "    \"urban_infra\",\n",
    "]\n",
    "df_list = []\n",
    "for sector in sector_list:\n",
    "    print(f\"Processing {sector} dataset\")\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(\n",
    "        f\"../data/{sector}_dataset.csv\", usecols=[\"title\", \"abstract\", \"true_label\"]\n",
    "    )\n",
    "    df = df[df[\"true_label\"] == \"About Sufficiency\"]\n",
    "    df[\"origin\"] = sector\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, ignore_index=True).dropna()\n",
    "df[\"true_label\"] = df[\"origin\"].astype(\"category\").cat.codes\n",
    "df.to_csv(\"../data/sector_positive.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb89ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       buildings       0.84      0.70      0.76       116\n",
      "  digitalisation       0.88      0.89      0.89       126\n",
      "         freight       1.00      0.19      0.31        27\n",
      "        mobility       0.84      0.99      0.91       753\n",
      "       nutrition       0.89      0.92      0.90       148\n",
      "   urban_ecology       0.68      0.27      0.39        48\n",
      "urban_governance       0.50      0.08      0.13        39\n",
      "     urban_infra       0.59      0.32      0.41        75\n",
      "\n",
      "        accuracy                           0.84      1332\n",
      "       macro avg       0.78      0.54      0.59      1332\n",
      "    weighted avg       0.82      0.84      0.81      1332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/sector_positive.csv\")\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"abstract\"], df[\"true_label\"], test_size=0.2, random_state=42, stratify=df[\"true_label\"]\n",
    ")\n",
    "\n",
    "# Traditional Classifier: Logistic Regression\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, train_labels)\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(classification_report(test_labels, lr_predictions, target_names=df[\"origin\"].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365b5601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='666' max='666' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [666/666 02:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.915600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.485200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.423400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Classifier Performance:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       buildings       0.86      0.88      0.87       116\n",
      "  digitalisation       0.81      0.96      0.88       126\n",
      "         freight       1.00      0.07      0.14        27\n",
      "        mobility       0.92      0.98      0.95       753\n",
      "       nutrition       0.93      0.93      0.93       148\n",
      "   urban_ecology       0.68      0.35      0.47        48\n",
      "urban_governance       0.92      0.28      0.43        39\n",
      "     urban_infra       0.55      0.52      0.53        75\n",
      "\n",
      "        accuracy                           0.88      1332\n",
      "       macro avg       0.83      0.62      0.65      1332\n",
      "    weighted avg       0.88      0.88      0.86      1332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BERT Classifier\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    \"bert-base-uncased\", cache_dir=\"../.cache\"\n",
    ")\n",
    "\n",
    "# Tokenize the dataset\n",
    "train_encodings = tokenizer(\n",
    "    list(train_texts), truncation=True, padding=True, max_length=512\n",
    ")\n",
    "test_encodings = tokenizer(\n",
    "    list(test_texts), truncation=True, padding=True, max_length=512\n",
    ")\n",
    "\n",
    "# Convert the data into Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": train_encodings[\"input_ids\"],\n",
    "        \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "        \"labels\": train_labels,\n",
    "    }\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": test_encodings[\"input_ids\"],\n",
    "        \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "        \"labels\": test_labels,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load the BERT model\n",
    "bert_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(df[\"true_label\"].unique()),\n",
    "    cache_dir=\"../.cache\",\n",
    ")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=200,\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Train the BERT model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the BERT model\n",
    "bert_predictions = trainer.predict(test_dataset)\n",
    "bert_predicted_labels = bert_predictions.predictions.argmax(axis=1)\n",
    "\n",
    "print(\"BERT Classifier Performance:\")\n",
    "print(classification_report(test_labels, bert_predicted_labels, target_names=df[\"origin\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ebe973",
   "metadata": {},
   "source": [
    "# SciBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f701a1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='167' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [167/167 02:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.992900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.474500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.400200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Classifier Performance:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       buildings       0.88      0.84      0.86       116\n",
      "  digitalisation       0.83      0.95      0.89       126\n",
      "         freight       0.91      0.37      0.53        27\n",
      "        mobility       0.93      0.98      0.95       753\n",
      "       nutrition       0.92      0.95      0.93       148\n",
      "   urban_ecology       0.71      0.42      0.53        48\n",
      "urban_governance       0.86      0.46      0.60        39\n",
      "     urban_infra       0.59      0.55      0.57        75\n",
      "\n",
      "        accuracy                           0.89      1332\n",
      "       macro avg       0.83      0.69      0.73      1332\n",
      "    weighted avg       0.88      0.89      0.88      1332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, cache_dir=\"../.cache\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "train_encodings = tokenizer(\n",
    "    list(train_texts), truncation=True, padding=True, max_length=512\n",
    ")\n",
    "test_encodings = tokenizer(\n",
    "    list(test_texts), truncation=True, padding=True, max_length=512\n",
    ")\n",
    "\n",
    "# Convert the data into Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": train_encodings[\"input_ids\"],\n",
    "        \"attention_mask\": train_encodings[\"attention_mask\"],\n",
    "        \"labels\": train_labels,\n",
    "    }\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": test_encodings[\"input_ids\"],\n",
    "        \"attention_mask\": test_encodings[\"attention_mask\"],\n",
    "        \"labels\": test_labels,\n",
    "    }\n",
    ")\n",
    "bert_model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(df[\"true_label\"].unique()), cache_dir=\"../.cache\"\n",
    ")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Train the BERT model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the BERT model\n",
    "bert_predictions = trainer.predict(test_dataset)\n",
    "bert_predicted_labels = bert_predictions.predictions.argmax(axis=1)\n",
    "\n",
    "print(\"BERT Classifier Performance:\")\n",
    "print(classification_report(test_labels, bert_predicted_labels, target_names=df[\"origin\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4033290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Democratiser la sobri√©t√© (refonte du README en cours)

Un projet visant √† d√©mocratiser les approches de sobri√©t√© gr√¢ce √† un syst√®me RAG (Retrieval-Augmented Generation) et des outils d'analyse automatis√©e.


## Pr√©sentation du projet

Le projet est structur√© en plusieurs sous-projets :

- **Visualisation** (branche `visualizations-combined` non encore merg√©e) :
    - [Carbon budget](https://app-d066b92e-20ba-4dbf-af25-73c7e5657091.cleverapps.io/) : budget carbone restant par pays pour rester sour les 2¬∞C de r√©chauffement
    - D√©composition [monde](https://app-e1c3f118-5441-449a-99f3-fa4036bb2ad4.cleverapps.io/) et [UE](https://app-ac31ad44-d32f-4998-87c6-b9b699c29c63.cleverapps.io/) de sc√©narios de d√©carbonation en Population - D√©carbonation - Efficacit√© √©nerg√©tique - Sobri√©t√©
    - [Indicateurs de bien-√™tre](https://app-aa62786e-21f6-42ab-b0ff-ddca6575e4f8.cleverapps.io/) (EWBI)
- **Library** : base d'articles sur la sobri√©t√© dans `src`
- **Policy analysis** (dans `rag_system/policy_analysis`) : pipeline d'extraction et d'analyse de politiques de sobri√©t√© et de leurs impacts dont les r√©sultats ont vocation √† √™tre inclus dans le RAG
- **ChatSufficiency** (dans `rag_system`) : chatbot destin√© aux experts des politiques publiques, branch√©s en RAG sur la library et les r√©sultats de la policy analysis

De plus, une **taxonomie** a √©t√© d√©velopp√©e visant √† enrichir les articles de la library de m√©tadonn√©es "m√©tier" (en plus des m√©tadonn√©es issues d'OpenAlex) via un traitement par LLM. Celle-ci est pr√©sente en double dans le code, dans `rag_system/taxonomy` et `src/wsl_library_domain`.

Un refactoring est pr√©vu pour √©liminer ce doublon, mieux s√©parer les sous-projet et remplacer la librairie de RAG Kotaemon par du code custom.


## Library
### 1. Pr√©-screening
La source de d√©part est OpenAlex.
L'int√©gration de sources alternatives est laiss√©e √† de futurs travaux.
Le pr√©-screening √† partir d'OpenAlex es fait en deux √©tapes :
1. Ensemble de requ√™tes par mots-cl√©s (choisis par des experts) √† l'API OpenAlex -> 1.6M d'articles
2. Filtrage des articles par une classification `about sufficiency / not about sufficiency` fond√©e sur leur abstract.

L'√©tape 2 a √©t√© effectu√©e et [document√©e](https://theolvs.notion.site/Documentation-et-m-thodo-Pr-screening-1f8819109fa4807b842ecd568785004c) par Th√©o Alves avec un mod√®le BERT entra√Æn√© avec SetFit sur un dataset annot√© √† la main, ce qui a conduit √† garder 250k articles.
Ce code n'est pas (encore) sur le repo GitHub mais il est disponible [sur Collab](https://colab.research.google.com/drive/1onirKPHdBxHTqcQKGOTgupNVpbgCJQgz?usp=sharing), le mod√®le entra√Æn√© [sur HuggingFace](https://huggingface.co/TheoLvs/wsl-prescreening-multi-v0.0/tree/main) et les jeu de donn√©es [sur Drive](https://drive.google.com/drive/folders/1EQkQQaUN11jvZAeP8Uf5YFC9yjLCs2Kx).
Th√©o rapporte une accuracy sur le dataset de test (20% du dataset annot√©) de 100%, mais le recall r√©el (m√©trique la plus importante) est inconnu.
Les articles s√©lectionn√©s sont stock√©s dans la table `policies_abstracts_all` de la base postgres (ID OpenAlex, DOI et abstract, √©trangement sans leur titre).

Des tentatives d'am√©lioration de l'√©tape 2 ont √©t√© effectu√©es sans √™tre utilis√©es :
- dans la branche `feature/pre-screening` avec des API d'IA g√©n√©rative (Mistral, OpenAI) ;
- dans la branche `prescreening-experimentation` avec un entra√Ænement de mod√®les BERT (dont SciBERT) par pytorch-lightning.

La fonction `search_openalex` de `src/wsl_library/scraping/extract_openalex.py` permet quant √† elle de reproduire l'√©tape 1.
L'ensemble de mots-cl√©s √† utiliser ne semble toutefois pas document√©.

### 2. Extraction full-text
Cette √©tape regroupe √† nouveau deux sous-√©tapes :
1. Obtention quand disponible (open access) d'un lien pour le texte complet, g√©n√©ralement en PDF.
2. T√©l√©chargement et lecture du PDF pour obtenir le texte converti en format markdown.

Les PDF t√©l√©charg√©s doivent √™tre stock√©s pour affichage aux utilisateurs finaux quand ils sont cit√©s.

Le code pour l'√©tape 1 (√† perfectionner car il ne g√®re pas les cas o√π il faut cliquer sur une popup avant d'acc√©der au PDF) est dans `src/wsl_library/scraping/extract_openalex.py` et celui de l'√©tape 2 dans `src/wsl_library/pdfextraction/pdf/`.

### 3. Extraction des m√©tadonn√©es
En plus des m√©tadonn√©es d'OpenAlex, des m√©tadonn√©es "m√©tier" correspondant √† la taxonomie sont ajout√©es par un traitement LLM (API DeepSeek) aux articles.
Les petits mod√®les n'ayant pas des performances satisfaisantes sur cette t√¢che, il est recommand√© d'utiliser des mod√®les d'au moins 50-60 Md de param√®tres (totaux pour les MoE).
Les contraintes de Kotaemon ont impos√© d'effectuer cette √©tape en m√™me temps que l'ingestion dans la base lancedb de Kotaemon (dans `rag_system/kotaemon_pipeline_scripts/fast_ingestion/`) mais elle est en principe distincte.
Du code est d'ailleurs disponible pour ce faire dans `src/wsl_library/pdfextraction/llm/`.

Le traitement des chunks pour cette √©tape reste √† clarifier (m√©tadonn√©es en propre ou copie de celles du document original).

### Policy analysis
A COMPLETER (EDOUARD)


### ChatSufficiency
A COMPLETER (Fran√ßois)


## üöÄ Quick Start


### 1. Installer les d√©pendances `uv` et `pip`

```bash
# macOS et Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# Alternative : via pip
pip install uv
```

Plus d'informations : [documentation officielle de uv](https://astral.sh/uv)


### 2. Lancer les precommit-hooks localement

[Installer les precommit](https://pre-commit.com/)

    pre-commit run --all-files

### 3. Utiliser Tox pour tester votre code

    tox -vv


## Roadmap

- [ ] R√©duire les requirements dans `rag_system`
- [ ] Fusionner `rag_system` et `src` dans un seul dossier
- [ ] Ajouter des tests unitaires
- [ ] Ajouter des tests d'int√©gration
- [ ] Am√©liorer la documentation
- [ ] Am√©liorer l'extraction de politiques de sobri√©t√©


> [!IMPORTANT]
> Projet en d√©veloppement actif, pas de garantie de fonctionnement, notamment pour les tests.
